---
marp: true
paginate: true
math: mathjax

style: |
    section.title {
        --title-height: 130px;
        --subtitle-height: 70px;

        font-family: 'Meiryo UI';
        overflow: visible;
        display: grid;
        grid-template-columns: 1fr;
        grid-template-rows: 1fr var(--title-height) var(--subtitle-height) 1fr;
        grid-template-areas: "." "title" "subtitle" ".";
    }

    section.title h2 {
        margin: 0;
        padding: 0;
        text-align: center;
        height: var(--area-height);
        line-height: var(--area-height);
        font-size: calc(var(--area-height) * 0.7);

        border: 1px dashed gray; /* debug */
    }

    section.title h1 {
        color: #0445FF;
        font-weight: bold;
        font-family: 'Meiryo UI';

    }

    section.title h2 {
        grid-area: subtitle;
        --area-height: var(--subtitle-height);
    }

    section {
        justify-content: start;
        font-family: 'Meiryo UI'
    }

    .title-slide {
    display: grid;
    place-items: center; /* 中央揃え */
    height: 100vh; /* スライド全体の高さ */
    }
---
---
---
---
---
---
---
---
---
<br>
<br>
<br>
<br>
<br>
<br>
<br>

# STEP 1


---
# VAE（変分オートエンコーダー）におけるELBO
独立のガウス分布 $x,y$ と、その和 $z$ を考えると、（変分オートエンコーダー）において、VAE の $ELBO$ は次式、

$$
\begin{align}
    ELBO(y;\theta, \phi) 

    &= \int q_{\phi}(z \mid x) \log \frac{p_{\theta}(x \mid z)}{q_{\phi}(z \mid x)} dz\\

    &= \mathbb{E}_{q_{\phi}(z \mid x)} \left[ \log \frac{p_{\theta}(x \mid z)}{q_{\phi}(z \mid x)} \right]
    \tag{1}
\end{align}
$$
となる。

---
# 拡散モデルのELBO
前スライドの $(1)$ 式から拡散モデルにするために、

- 画像 $x$ を、タイムステップを考慮して $x_{0}$ 
- 潜在変数 $z$ を $x_{1}, x_{2}, \cdots, x_{T}$ へ変更
- パラメータ $\phi$ を削除

このように変更すると拡散モデルの $ELBO$ は、
$$
\begin{align}
    ELBO(x_{0};\theta)
    
    = \mathbb{E}_{q_{\phi}(x_{1}, x_{2}, \cdots, x_{T} \mid x_0)} \left[ \log \frac{p_{\theta}(x_{0}, x_{1}, \cdots, x_{T})}{q_{\phi}(z \mid x)} \right]
    \tag{2}
\end{align}
$$
となり、$x_{0}, x_{1}, \cdots, x_{T}$ を $x_{0:T}$ とすると、 $(2)$ 式は次式で表せる。
$$
\begin{align}
    ELBO(x_{0};\theta)
    
    = \mathbb{E}_{q(x_1:T \mid x_0)} \left[ \log \frac{p_\theta(x_{0:T})}{p_\theta(x_{1:T} \mid x_0)} \right]
    \tag{3}
\end{align}
$$

---
# ELBOの式展開
ここではELBOの式展開を進めていきます。まずはELBOの式(8.2)に出てくる式の $p_0(x_{0:T})$ です。これは連続型確率変数マルコフ連鎖により次の式で表されます。
$$
\begin{align}
    p_\theta(x_{0:T}) 

    &= p_\theta(x_\theta \mid x_1) p_\theta(c_1 \mid x_1) \ldots p_\theta(x_{T-1} \mid x_T) p(x_T)\\

    &= p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t)\tag{4}
\end{align}
$$
ここで最終時刻の $p(x_T)$ は、完全なガウスノイズ $N(x_T; 0,1)$ を表します。
次に $q(x_{1:T} \mid x_0)$ を乗法定理とマルコフ性より次式で表されます。
$$
q(x_{1:T} \mid x_0) = \prod_{t=1}^T q(x_t \mid x_{t-1})\tag{5}
$$

---
# ELBOの式展開 -2
先ほどの式より、ELBOは次式で表されます。
$$
\begin{align}
    \text{ELBO}(q) 

    &= \mathbb{E}_{q(x_1:T \mid x_0)} \left[ \log \frac{p_\theta(x_{0:T})}{p_\theta(x_{1:T} \mid x_0)} \right]\\

    &= \mathbb{E}_{q(x_1:T \mid x_0)} \left[ \log \frac{p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t)}{\prod_{t=1}^T q(x_t \mid x_{t-1})} \right]\\
\end{align}
$$
$$
\begin{align}
    &= \mathbb{E}_{q(x_1:T \mid x_0)} \left[ \log \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t) + \boxed{\log \frac{p(x_T)}{\prod_{t=1}^T q(x_t \mid x_{t-1})} } \right]\tag{6}
\end{align}
$$

ここで、ELBOを0に関して最適化することが目的なので、ELBOの中で0を含まない、上記の□で囲った項は無視することができます。

---
# ELBOの式展開 -3
$J(\theta)$ という式で目的関数(= 最大化する対象)を表すと、
$$
\begin{align}
J(\theta) 

&= \mathbb{E}_{q(x{1:T} \mid x_0)} \left[ \log \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t) \right]\\

&= \mathbb{E}_{q(x{1:T} \mid x_0)} \left[ \sum_{t=1}^T \log p_\theta(x_{t-1} \mid x_t) \right]
\tag{7}
\end{align}
$$

ここで、モンテカルロ法のサンプルサイズを1とすると、

$$
\begin{align}
x_{1: T} 

&\sim q\left(x_{1: T} \mid x_{0}\right) \tag{8}\\

J(\theta) 

&\approx \sum_{t=1}^{T} \log p_{\theta}\left(x_{t-1} \mid x_{t}\right)\tag{9}
\end{align}
$$

---
# 目的関数の導出
ここで、元のデータ $\boldsymbol{x}_{0}$ から拡散ステップを開始し、$\boldsymbol{x}_{1:T}$を生成。その $\boldsymbol{x}_{1:T}$ を用いて各時刻における$\log p_{\theta}(\boldsymbol{x}_{t-1} | \boldsymbol{x}_{t})$を計算すると仮定する。

$$
\begin{align}
\hat{x}_{t-1} 
= \operatorname{NeuralNet}\left(\boldsymbol{x}_{t}, t ; \boldsymbol{\theta}\right) \tag{10}\\
p_{\theta}\left(x_{t-1} \mid \boldsymbol{x}_{t}\right) = \mathcal{N}\left(\boldsymbol{x}_{t-1} ; \hat{\boldsymbol{x}}_{t-1}, \mathbf{I}\right)\tag{11}
\end{align}
$$
より、目的関数 $J(\theta)$ は、
$$
\begin{align}
J(\theta) 
& \approx \sum_{t=1}^{T} \log p_{\theta}\left(x_{t-1} \mid x_{t}\right) \\
& = \sum_{t=1}^{T} \log \mathcal{N}\left(x_{t-1} ; \hat{x}_{t-1}, \mathrm{I}\right) \\
\end{align}
$$

---
# 目的関数の導出 -2
$$
\begin{align}
& = \sum_{t=0}^{T-1} \log \mathcal{N}\left(x_{t} ; \hat{x}_{t}, \mathbf{I}\right) \quad \text{（} t \text{ の聞始番号を変更）} \\

& = \sum_{t=0}^{T-1} \log \frac{1}{\sqrt{(2 \pi)^{D}|\mathbf{I}|}} \exp \left\{ -\frac{1}{2}\left(x_{t}-\hat{x}_{t}\right)^{\top} \mathbf{I}^{-1} \left(x_{t}-\hat{x}_{t}\right) \right\}  \text{（} t \text{ 正規分布の式を代入}\text{）}  \\

& = \sum_{t=0}^{T-1} \left( -\frac{1}{2}\left(x_{t}-\hat{x}_{t}\right)^{\top}\left(x_{t}-\hat{x}_{t}\right) + \log \frac{1}{\sqrt{(2 \pi)^{D}}} \right) \quad \left( |\mathbf{I}|=1, \quad \mathbf{I}^{-1}=\mathrm{I} \right) \\

& = -\frac{1}{2} \sum_{t=0}^{T-1} \left(x_{t}-\hat{x}_{t}\right)^{\top}\left(x_{t}-\hat{x}_{t}\right) + \boxed{T \log \frac{1}{\sqrt{(2 \pi)^{D}}} }\text{（定数）} \\

& = -\frac{1}{2} \sum_{t=0}^{T-1} \left|\left| x_{t}-\hat{x}_{t}\right|\right| ^{2} \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad(12)
\end{align}
$$

---
# 目的関数の導出 -3
したがって、ここまでの結果から、目的関数 $J(\theta) $ は次に示すステップで求めることができることが分かる。

1. 拡散過程により $T$ 個のサンプリングを行う
2. ニューラルネットワークを $T$ 回適用してノイズを除去
3. 各時刻における2乗誤差 $||x_{t}-\hat{x}_{t}||^{2}$ を求める

しかしながら、上記の 1 ~ 3の順で求めると、計算がすごく大変…。

次スライド以降から、この計算を近似で軽くする手法を考える。

---
<br>
<br>
<br>
<br>
<br>
<br>
<br>

# STEP 2

---
# ELBOの近似
$(7)$ 式から、
$$
\begin{align}
J(\theta) & =\mathbb{E}_{q\left(\boldsymbol{x}_{1: T} \mid \boldsymbol{x}_{0}\right)}\left[\sum_{t=1}^{T} \log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right] \\

& =\sum_{t=1}^{T} \mathbb{E}_{q\left(\boldsymbol{x}_{1: T} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right] \text{（期待値の線形性）} (13)\\

& =\sum_{t=1}^{T} \mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right]
\text{（関連する変数の期待値）}(14)
\end{align}
$$

---
# 一様分布の期待値
$1$ から $T$ までの一様分布における確率分布を $u(t)$ とすると、
$$
\begin{align}
    \mathbb{E}_{u(t)}[f(t)]
    
    &= \sum_{t=1}^{T} u(t)f(t)\\
    
    &= \sum_{t=1}^{T} \frac{1}{T} f(t)\\

    &= \frac{1}{T}\sum_{t=1}^{T} f(t)\\

    \Leftrightarrow \sum_{t=1}^{T} f(t) &= T\ \mathbb{E}_{u(t)}[f(t)] \tag{15}
\end{align}
$$

---
# $ELBO$の近似
$$
\begin{align}
J(\theta) 

& =\sum_{t=1}^{T} \mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right] \\

&= T \ \mathbb{E}_{u(t)}[\mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right]] \tag{16}
\end{align}
$$

この式をモンテカルロ法によって近似計算すると、

$$
\begin{align}
J(\theta) 

& \approx T\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\tag{17}
\end{align}
$$
となる。ここで $(12)$ 式で導出したように、ガウス分布の対数尤度は2乗誤差に帰着するため、
$$
\begin{align}
J(\theta) 
& \approx -\frac{T}{2} \left|\left| x_{t-1}-\hat{x}_{t-1}\right|\right| ^{2} \tag{18}
\end{align}
$$
となる、これが拡散モデルにおける目的関数（$ELBO$）の近似式である。

---
# $ELBO$の近似 -2
したがって、ここまでの結果から、目的関数 $J(\theta)$ は近似によって、次に示すステップで求めることができることが分かる。

1. 一様分布 $U \{1, T \}$ から時刻 $t$ をサンプリング
2. $q(x_{t-1},x_0)$ から $x_{t-1}$ をサンプリングし、次に$q(x_{t},x_{t-1})$ から $x_{t}$ をサンプリングする
3. ニューラルネットワークに $x_{t}$ を入力して $\hat{x}_{t-1}$ を出力する
4. 2乗誤差 $||x_{t-1}-\hat{x}_{t-1}||^{2}$ を求める



---
# $q(x_t \mid x_0)$ の導出
ここで、入力画像からガウスノイズを連続して付与する処理について考える。
独立のガウス分布 $x,y$ と、その和 $z$ を考え次式で定義する。
$$
\begin{align}
x
&\sim \mathcal{N}(\mu_x, \sigma^2_x) \tag{19}\\
y
&\sim \mathcal{N}(\mu_y, \sigma^2_y) \tag{20}\\
z
&= x+y \tag{21}
\end{align}
$$

ガウスノイズの和はガウスノイズであることから、$z$ は1つのガウス分布からのサンプルとして考えることができる。この性質を利用すると次式、

$$
\begin{align}
z
&\sim \mathcal{N}(\mu_x+\mu_y, \sigma^2_x+\sigma^2_y) \tag{21}\\  
\end{align}
$$

で表すことができる。

---
# ガウス過程におけるノイズの定義
ここで、付与するガウスノイズについてスケジューリングすることを考える。具体的には、付与するガウスノイズについて時間経過とともに、次第に小さくなることを考えると、拡散過程におけるガウスノイズ $q(x_t \mid x_t-1)$ は次式、

$$
\begin{align}
q(x_t \mid x_t-1)
&= \mathcal{N}(x_t\sqrt{1-\beta_t}x_t -1, \beta_t \boldsymbol{I}) \tag{22}\\  
\end{align}
$$

で表すことができる。ただし、$\boldsymbol{I}$ を単位行列、$\beta_t$ はユーザが任意で設定するスケジューラのパラメータとし、 $\beta_{1},\beta_{2},\cdots,\beta_{T}$ とする。例えば、$\beta_1$ を $0.01$ として、タイムステップごとに $0.01 \sim 0.0001$ に変化する関数のように設計できる。このスケジューラ自体はコサインアニーリングなど様々存在するので割愛。
また、$(22)$ 式は長いので、$\alpha_t = 1 - \beta_t$ として、次式で示すことにする。

$$
\begin{align}
q(x_t \mid x_t-1)
&= \mathcal{N}(x_t\sqrt{\alpha_t}x_t -1, (1-\alpha_t) \boldsymbol{I}) \tag{23}\\  
\end{align}
$$

----
# $q(x_t \mid x_0)$ の導出 -2
ここで、$\text{VAE}$ 同様に変数変換（再パラメータ化）トリックを使用して

$$
\begin{align}
\varepsilon_t
&\sim \mathcal{N}(0,\boldsymbol{I}) \tag{24}\\
x_{t}
&=\sqrt{\alpha_{t}} x_{t-1}+\sqrt{1-\alpha_{t} }\varepsilon_{t}
\tag{25}
\end{align}
$$
と表すことができる。ここで、$t$ に $t-1$ を代入して、
$$
\begin{align}
\varepsilon_{t-1}
&\sim \mathcal{N}(0,\boldsymbol{I}) \tag{26}\\
x_{t-1}
&=\sqrt{\alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_{t-1} }\varepsilon_{t-1}\tag{27}
\end{align}
$$
そして、これらの $(24)\sim(27)$ 式を利用すると、次式が求まる。

---
# $q(x_t \mid x_0)$ の導出 -3
$$
\begin{align}
x_{t} 
& =\sqrt{\alpha_{t}} x_{t-1}+\sqrt{1-\alpha_{t}} \varepsilon_{t} \\
& =\sqrt{\alpha_{t}}\left(\sqrt{\alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_{t-1}} \varepsilon_{t-1}\right)+\sqrt{1-\alpha_{t}} \varepsilon_{t} \\
& =\sqrt{\alpha_{t} \alpha_{t-1}} x_{t-2}+ \boxed{\sqrt{\alpha_{t}-\alpha_{t} \alpha_{t-1}} \varepsilon_{t-1}+\sqrt{1-\alpha_{t}} \varepsilon_{t}}\tag{28}
\end{align}
$$

ここでがガウスノイズの和の性質より、$(28)$ 式における□の部分は、1つの正規分布で表すことが
できるため、

$$
\begin{align}
\varepsilon
&\sim \mathcal{N}(0,\boldsymbol{I}) \tag{29}\\
x_{t}
&=\sqrt{\alpha_{t} \alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_{t} \alpha_{t-1} }\varepsilon\tag{30}
\end{align}
$$

となる。

---
# $q(x_t \mid x_0)$ の導出 -4
先ほどの数式変形を、$x_{t-2}, x_{t-3}, x_{t-4} \cdots$ と逐次的に繰り返すと、最終的に次式が得られる。
$$
\begin{align}
x_{t} & =\sqrt{\alpha_{t} \alpha_{t-1} \cdots \alpha_{1}} x_{0}+\sqrt{1-\alpha_{t} \alpha_{t-1} \cdots \alpha_{1}} \varepsilon \\
& =\sqrt{\bar{\alpha}_{t}} x_{0} + \sqrt{1-\bar{\alpha}_{t}} \varepsilon \tag{31}
\end{align}
$$

ただし、$\bar{\alpha}_t$ を $\alpha_{t} \alpha_{t-1} \cdots \alpha_{1}$ とする。

よって、$q\left(x_{t} \mid x_{0}\right)$ は

$$
\begin{align}
q\left(x_{t} \mid x_{0}\right)
=\mathcal{N}\left(x_{t} ; \sqrt{\bar{\alpha}_{t}} x_{0},\left(1-\bar{\alpha}_{t}\right) \mathbf{I}\right) \tag{32}
\end{align}
$$

となる。

---
<br>
<br>
<br>
<br>
<br>
<br>
<br>

# STEP 3

---
# $ELBO$の近似 -3
$(16)$ から、
$$
\begin{align}
J(\theta) 

& =\sum_{t=1}^{T} \mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right] \\

&= T \quad \mathbb{E}_{u(t)}[\mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right]] \tag{16}
\end{align}
$$

を得た。
ここで、$\mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)\right]$ を $J_0$ と定義する。すなわち、次式、

$$
\begin{align}
J(\theta) 
&= T \ \mathbb{E}_{u(t)}\left[ J_0 \right] \tag{33}
\end{align}
$$

で定義する。

---
# $ELBO$の近似 -4
ここで、$(33)$ 式において、我々はモンテカルロ法を用いることで、パラメータ $\theta \left( = \left\{ \text{(平均), (標準偏差)} \right\} \right)$ について最適化を行っている。
つまり、$\theta$ に関係がなければ、便宜のために適当な数を $(33)$ 式に加えても問題ないため、ここで、次式のように変形する。

$$
\begin{align}
\underset{\theta}{\arg \max } J_{0}

&= \underset{\theta}{\arg \max }\ \Bigg( J_{0}-\underbrace{\mathbb{E}_{q\left(x_{t-1}, x_{t} \mid x_{0}\right)}\left[\log q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right)\right]}_{\text {定数 }}\Bigg)\\

&= \underset{\boldsymbol{\theta}}{\arg \max }\ \mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t} \mid \boldsymbol{x}_{0}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}\right)-\log q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right)\right] \\

&=\underset{\boldsymbol{\theta}}{\arg \max }\ \underbrace{\mathbb{E}_{q\left(\boldsymbol{x}_{t-1}, x_{t} \mid x_{0}\right)}\left[\log \frac{p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid x_{t}\right)}{q\left(x_{t-1} \mid x_{t}, x_{0}\right)}\right]}_{J_{1}} \quad\quad\quad(34)\\
\end{align}
$$

---
# $ELBO$の近似 -5
ここでは $(34)$ 式の項を $J_{1}$ とする。 
$J_{0}$ と $J_{1}$ は最大となる $\boldsymbol{\theta}$ が同じため、次の $J_{1}$ を使った式を目的関数にできる。

$$
\begin{align}
J(\theta)=T\ \mathbb{E}_{u(t)}\left[J_{1}\right]
\end{align}
$$

続いて、 $J_{1}$ を次のように式展開します。
$$
\begin{align}
J_{1} & =\int q\left(x_{t-1}, x_{t} \mid x_{0}\right) \log \frac{p_{\theta}\left(x_{t-1} \mid x_{t}\right)}{q\left(x_{t-1} \mid x_{t}, x_{0}\right)} d x_{t-1} d x_{t} \\
& =\int q\left(x_{t} \mid x_{0}\right) q\left(x_{t-1} \mid x_{t}, x_{0}\right) \log \frac{p_{\theta}\left(x_{t-1} \mid x_{t}\right)}{q\left(x_{t-1} \mid x_{t}, x_{0}\right)} d x_{t-1} d x_{t} \\
\end{align}
$$

---
# $ELBO$の近似 -6
（続き）
$$
\begin{align}
& =-\int q\left(x_{t} \mid x_{0}\right) \underbrace{\int q\left(x_{t-1} \mid x_{t}, x_{0}\right) \log \frac{q\left(x_{t-1} \mid x_{t}, x_{0}\right)}{p_{\theta}\left(x_{t-1} \mid x_{t}\right)} d x_{t-1}}_{\mathrm{KL} \text { タイバージェンス }} d x_{t} \\
& =-\mathbb{E}_{q\left(\boldsymbol{x}_{t} \mid x_{0}\right)}\left[D_{\mathrm{KL}}\left(q\left(x_{t-1} \mid x_{t}, x_{0}\right) \| p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid x_{t}\right)\right)\right]
\tag{35}
\end{align}
$$

<br>

ここでは確率の乗法定理を使って展開します。最終的に$J_{1}$ は、「$q\left(x_{t} \mid x_{0}\right)$ に関する $\text{KL}$ ダイバージェンスの期待値」として表される。
$(35)$ 式はモンテカルロ法を使えば、**$x_{t}$ のサンブル 1 つだけで近似できます**。

---
# $ELBO$の近似 -7
また、KLタイバージェンスは２つの確率分布が等しいときに最小値（＝0）を取る。
$J_{1}$ は「マイナスの$\mathrm{KL}$ ダイバージェンス」なので、2つの確率分布が等しい$\theta\left(x_{t-1} \mid x_{t}\right)=q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ のときに最大になる。

つまり、ここでの目標は、$p_{\theta}\left(x_{t-1} \mid x_{t}\right)$ を$q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ に一致させることである。
$q\left(x_{t}\right)$ は正規分布として表されます。そのため、次式のように正規分布としてモデル化する。

$$
\begin{align}
\hat{x}_{t-1}

&=\operatorname{NeuralNet}\left(x_{t}, t ; \boldsymbol{\theta}\right)\tag{36} \\

p_{\theta}\left(x_{t-1} \mid x_{t}\right)

&=\mathcal{N}\left(x_{t-1} ; \hat{x}_{t-1}, \sigma_{q}^{2}(t) \mathbf{I}\right)\tag{37}
\end{align}
$$

---
# $ELBO$の近似 -8
$p_{\theta}\left(x_{t-1} \mid x_{t}\right)$ の平均べクトルは、ニューラルネットワークによって求める。
そして $p_\theta\left(x_{t-1} \mid x_{t}\right)$ の共分散行列は、 $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ と同じ値 $\Big( \sigma_{q}^{2}(t) \mathbf{I} \Big)$に設定する。ここで、これ以降はニューラルネットワークを $\mu_{\theta}\left(x_{t}, t\right)$ と簡略化して表す。
これにより、$(37)$ 式を次式、

$$
\begin{align}
p_{\theta}\left(x_{t-1} \mid x_{t}\right)=\mathcal{N}\left(x_{t-1} ; \mu_{\theta}\left(x_{t}, t\right), \sigma_{q}^{2}(t) \mathbf{I}\right)\tag{38}
\end{align}
$$

が成立する。

---
# [補足] 前スライドで$p_\theta\left(x_{t-1} \mid x_{t}\right)$ の共分散行列を $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ とする理由

## **[解答]**
$KL$ ダイバージェンス ${\int q\left(x_{t-1} \mid x_{t}, x_{0}\right) \log \frac{q\left(x_{t-1} \mid x_{t}, x_{0}\right)}{p_{\theta}\left(x_{t-1} \mid x_{t}\right)} d x_{t-1}}$ にが最小値 $(=0)$ をとるため。

目的関数の $J_{1}$ は**マイナスの** $KL$ ダイバージェンスであり、$J_{1}$ は $ELBO$ である。$ELBO$ は　尤度 $p_{\boldsymbol{\theta}}\left(\boldsymbol{x}_{t-1} \mid x_{t}\right)$ の下界であり、これを最大化すると、必然的に（入力画像から潜在変数を得るための）尤度関数を最大化する、

**つまり、$KL$ ダイバージェンスの最小化は、入力画像の表現を得るための尤度最大化を意味する。**

---
# $ELBO$の近似 -9
次に $KL$ タイバージェンスの計算について、今回は $2$ つの正規分布の $KL$ ダイバージェンスであるため、これは次式のとおり解析的に求めることが可能。

$$
\begin{align}
D_{\mathrm{KL}}\left(q\left(x_{t-1} \mid x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} \mid x_{t}\right)\right)=\frac{1}{2 \sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2} \quad\quad(39)
\end{align}
$$

---
# $(39)$ 式の導出
$KL$ ダイバージェンスは定義より、

$$
\begin{align}
D_{\mathrm{KL}}\left(q(x) \mid p(x)\right) = \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)}  dx \tag{40}
\end{align}
$$

となる。
ここで、$p(x)$, および $q(x)$ の両方の確率密度関数が正規分布なので、計算を次式のように簡略化（テキストp. 161 参照、二つの確率密度関数を近づけるため、$1$ となる）。

$$
\begin{align}
D_{\mathrm{KL}}\left(q(x) \mid p(x)\right)

= -\frac{1}{2} \left( 1 + \log
\underbrace{\frac{\sigma_q^2}{\sigma_q^2}}_{1} - \frac{(\mu_q - \mu_p)^2}{\sigma_q^2} - \underbrace{\frac{\sigma_q^2}{\sigma_q^2}}_{1} \right)  \tag{41}
\end{align}
$$

---
# $(39)$ 式の導出 -2
$(41)$ 式に、$(36),(37)$ 式で定義した確率密度関数の情報を代入し、整理すると、
$$
\begin{align}
D_{\mathrm{KL}}\left(q\left(x_{t-1} \mid x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} \mid x_{t}\right)\right)

&= \frac{1}{2} \frac{(\mu_{q}(x_t, t) - \mu_{\theta}(x_t, x_0))^2}{\sigma_q^2(t)} \\

&= \frac{1}{2 \sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2} \quad\quad(39)
\end{align}
$$

となる。

---
# $ELBO$の近似 -10
よって、拡散モデルの目的関数は次式となる。
$$
\begin{align}
J(\theta)

= -T \mathbb{E}_{u(t)}\left[\mathbb{E}_{q\left(x_{t} \mid x_{0}\right)}\left[\frac{1}{2 \sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2}\right]\right] \tag{42}
\end{align}
$$

損失関数は目的関数にマイナスを付けることで求められる。
また、損失関数を定牧することは、オプティマイザの学習率の設定で調整可能。
そこで上の式を - $\frac{2}{T}$ 倍した値を損失関数に設定すると、

$$
\begin{align}
\operatorname{LOSS}\left(x_{0} ; \theta\right)

= \mathbb{E}_{u(t)}\left[\mathbb{E}_{q\left(x_{t} \mid x_{0}\right)}\left[\frac{1}{\sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2}\right]\right] \tag{43}
\end{align}
$$

以上が損失関数の計算方法である。

---
# 拡散モデルにおける損失関数
モンテカルロ法（サンブルサイズを 1 とする）を使うと、損失関数は次のように求められる。

<br>

$$
\begin{align}
t & \sim U\{1, T\} \tag{44}\\

x_{t} & \sim q\left(x_{t} \mid x_{0}\right) \tag{45}\\

\operatorname{LOSS}\left(x_{0} ; \theta\right) & =\frac{1}{\sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2}\tag{46}
\end{align}
$$

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出

最後に、 $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出を行う。 $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ はべイスの定理より
次式が成立する。

$$
\begin{align}
q\left(x_{t-1} \mid x_{t}, x_{0}\right)=\frac{q\left(x_{t} \mid x_{t-1}, x_{0}\right) q\left(x_{t-1} \mid x_{0}\right)}{q\left(x_{t} \mid x_{0}\right)}\tag{47}
\end{align}
$$

ここでマルコフ性により $q\left({x}_{t} \mid {x}_{t-1}, {x}_{0}\right)=q\left({x}_{t} \mid {x}_{t-1}\right)$ が成立する。よって、 $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ は次式で表される。

$$
\begin{align}
q\left(x_{t-1} \mid x_{t}, x_{0}\right)=\frac{q\left(x_{t} \mid x_{t-1}\right) q\left(x_{t-1} \mid x_{0}\right)}{q\left(x_{t} \mid x_{0}\right)}\tag{48}
\end{align}
$$

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -2
さて、拡散過程に関する確率分布について、これまで得た式は以下の通り。

$$
\begin{align}
q\left(x_{t} \mid x_{t-1}\right) 

& =\mathcal{N}\left(x_{t} ; \sqrt{\alpha_{t}} x_{t-1},\left(1-\alpha_{t}\right) \mathbf{I}\right) \tag{49} \\

q\left(x_{t} \mid x_{0}\right) & =\mathcal{N}\left(x_{t} ; \sqrt{\bar{\alpha_{t}}} x_{0},\left(1-\bar{\alpha}_{t}\right) \mathbf{I}\right) \tag{50}
\end{align}
$$

これより $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ は次式のように展開可能。

$$
\begin{align}
q\left(x_{t-1} \mid x_{t}, x_{0}\right) & =\frac{q\left(x_{t} \mid x_{t-1}\right) q\left(x_{t-1} \mid x_{0}\right)}{q\left(x_{t} \mid x_{0}\right)} \\
& =\frac{\mathcal{N}\left(x_{t} ; \sqrt{\alpha_{t}} x_{t-1},\left(1-\alpha_{t}\right) \mathbf{I}\right) \mathcal{N}\left(x_{t-1} ; \sqrt{\alpha_{t-1}} x_{0},\left(1-\bar{\alpha}_{t-1}\right) \mathbf{I}\right)}{\mathcal{N}\left(\boldsymbol{x}_{t} ; \sqrt{\bar{\alpha}_{t}} x_{0},\left(1-\bar{\alpha}_{t}\right) \mathbf{I}\right)} \quad(51)
\end{align}
$$

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -3
$(51)$ 式のとおり、 3 つの正規分布の積と除算によって表される。
そして、結果的に得られる $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ もまた正規分布となる。

## $q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right)$ か「どのような正規分布になるか」を計算

このような場合は、正規分布の指数部分に注目することで、効率的に式展開が可能。
具体的に、 $\mathcal{N}\left(x_{t} ; \sqrt{\alpha_{t}} x_{t-1},\left(1-\alpha_{t}\right) \mathbf{I}\right)$ の指数部分は次スライドで表される。

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -4
$$
\begin{align}
&\mathcal{N}\left(x_{t} ; \sqrt{\alpha_{t}} x_{t-1},\left(1-\alpha_{t}\right) \mathbf{I}\right) \\

&\varpropto \exp \left\{-\frac{1}{2}\left(x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right)^{\top}\left(\left(1-\alpha_{t}\right) \mathbf{I}\right)^{-1}\left(x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right)\right\} \\

&=  \exp \left\{-\frac{1}{2}\left(x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right)^{\top}\left(\frac{1}{1-\alpha_{t}} \mathbf{I}\right)\left(x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right)\right\} \\

&=  \exp \left(-\frac{1}{2} \frac{\left\|x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right\|^{2}}{1-\alpha_{t}}\right)
\tag{52}
\end{align}
$$

※ " **$\varpropto$** "は「比例する」を表す記号。

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -5
以上の点を踏まえて、 $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の指数部分に着目すると次の式展開ができる。

$$
\begin{align}
&q\left(x_{t-1} \mid x_{t}, x_{0}\right) \\

&\varpropto \exp\left(-\frac{1}{2}\left(\frac{\left\|x_{t}-\sqrt{\alpha_{t}} x_{t-1}\right\|^{2}}{1-\alpha_{t}}+\frac{\left\|x_{t-1}-\sqrt{\alpha_{t-1}} x_{0}\right\|^{2}}{1-\bar{\alpha}_{t-1}}

-\frac{\left\|x_{t}-\sqrt{\bar{\alpha}_{t}} x_{0}\right\|^{2}}{1-\bar{\alpha}_{t}}\right)\right) \\

&=\exp \left(-\frac{1}{2}\left(\frac{\left\|x_{t}\right\|^{2}-2 \sqrt{\alpha_{t}} x_{t} \cdot x_{t-1}+\alpha_{t}\left\|x_{t-1}\right\|^{2}}{1-\alpha_{t}}\right.\right. \\

& \quad\quad +\frac{\left\|x_{t-1}\right\|^{2}-2 \sqrt{\bar{\alpha}_{t-1}} x_{0} \cdot x_{t-1}+\bar{\alpha}_{t-1}\left\|x_{0}\right\|^{2}}{1-\bar{\alpha}_{t-1}} \left.\left. -\frac{\left\|x_{t}-\sqrt{\bar{\alpha}_{t}} x_{0}\right\|^{2}}{1-\bar{\alpha}_{t}}\right)\right) \\

&=\exp \left(-\frac{1}{2}\left(\left(\frac{\alpha_{t}}{1-\alpha_{t}}+\frac{1}{1-\bar{\alpha}_{t-1}}\right)\left\|x_{t-1}\right\|^{2}\right.\right. 

-\left(\frac{2 \sqrt{\alpha_{t}}}{1-\alpha_{t}} x_{t}+\frac{2 \sqrt{\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} x_{0}\right) \cdot x_{t-1} \left.\left.+C\left(x_{t}, x_{0}\right)\right)\right) \quad\quad(54)
\end{align}
$$

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -5
$q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ は $x_{t-1}$ の条件付き確率分布である。
ここで $C\left(x_{t}, x_{0}\right)$ は $x_{t-1}$ に 関係しない項を表す。続いて、$(54)$ 式を
<br>
$$
\begin{align}
\exp \left(-\frac{1}{2} \frac{\left\|x_{t-1}-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2}}{\sigma_{q}^{2}(t)}\right)
\tag{55}
\end{align}
$$

<br>

という形に変形することで、平均ベクトル $\mu_{q}\left(x_{t}, x_{0}\right)$ と分散 $\sigma_{q}^{2}(t)$ を求めることができまるため、式展開を行うと次スライドのようになる。

---
# $q\left(x_{t-1} \mid x_{t}, x_{0}\right)$ の導出 -6
$$
\begin{align}
\sigma_{q}^{2}(t)  

&=1 /\left(\frac{\alpha_{t}}{1-\alpha_{t}}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) 

= \frac{\left(1-\alpha_{t}\right)\left(1-\bar{\alpha}_{t-1}\right)}{\left(1-\bar{\alpha}_{t-1}\right) \alpha_{t}+1-\alpha_{t}} 

= \frac{\left(1-\alpha_{t}\right)\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_{t}} \\


\mu_{q}\left(x_{t}, x_{0}\right)

&= \left(\frac{\sqrt{\alpha_{t}}}{1-\alpha_{t}} x_{t}+\frac{\sqrt{\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} x_{0}\right) /\left(\frac{\alpha_{t}}{1-\alpha_{t}}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) \\

&= \left(\frac{\sqrt{\alpha_{t}}}{1-\alpha_{t}} x_{t}+\frac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} x_{0}\right) / \frac{1-\bar{\alpha}_{t}}{\left(1-\alpha_{t}\right)\left(1-\bar{\alpha}_{t-1}\right)} \\

&= \frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right) x_{t}+\sqrt{\alpha_{t-1}}\left(1-\alpha_{t}\right) x_{0}}{1-\bar{\alpha}_{t}} \quad\quad(56)
\end{align}
$$

これより次式を得ることができた。

$$
\begin{align}
q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_{t}, \boldsymbol{x}_{0}\right) 

=\mathcal{N}(x_{t-1} ; \underbrace{\frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right) x_{t}+\sqrt{\bar{\alpha}_{t-1}}\left(1-\alpha_{t}\right) x_{0}}{1-\bar{\alpha}_{t}}}_{\mu_{q}\left(x_{t}, x_{0}\right)}, \underbrace{\frac{\left(1-\alpha_{t}\right)\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_{t}}}_{\sigma_{q}^{2}(t)} \mathbf{I}) 
\quad(57)
\end{align}
$$

---
<br>
<br>
<br>
<br>
<br>
<br>
<br>

# AppendiX（追加説明）

---
# （これまで学習した）拡散モデルの学習アルゴリズム
1. Repeat.
2. $\quad x_{0}$ を学習データよりランダムに取得
3. $\quad t \sim U\{1, T\} \quad$ (一様分布より整数 $t$ を生成)
4. $\quad \varepsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$
5. $\quad x_{t}=\sqrt{\bar{\alpha}_{t}} x_{0}+\sqrt{1-\bar{\alpha}_{t}} \varepsilon \quad\left(q\left(x_{t} \mid x_{0}\right)\right.$ からのサンプル
6. $\quad \mu_{q}\left(x_{t}, x_{0}\right)=\frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right) x_{t}+\sqrt{\bar{\alpha}_{t-1}}\left(1-\alpha_{t}\right) x_{0}}{1-\bar{\alpha}_{t}}$
7. $\quad \sigma_{q}^{2}(t)=\frac{\left(1-\alpha_{t}\right)\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_{t}}$
8. $\quad \operatorname{LOSS}\left(x_{0} ; \theta\right)=\frac{1}{\sigma_{q}^{2}(t)} \| \mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_0\right) \|^2$
9. $\quad \frac{\partial}{\partial \theta}\operatorname{LOSS}\left(x_{0} ; \theta\right)$ を求め、勾配法でパラメータを更新

---
# （これまで学習した）拡散モデルの学習アルゴリズム -2

---
# 拡散モデルの学習アルゴリズム
## 元データを復元するニューラルネットワーク
$(56)$ 式より、

$$
\begin{align}
\mu_{q}\left(x_{t}, x_{0}\right)

= \frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right) x_{t}+\sqrt{\alpha_{t-1}}\left(1-\alpha_{t}\right) \color{red}x_{0}}{1-\bar{\alpha}_{t}} \quad\quad(56)
\end{align}
$$

また、エンコーダ側を $\mu_{q}\left(x_{t}, x_{0}\right)$ に対応させると次式、

$$
\begin{align}
\mu_{\theta}\left(x_{t}, t\right)

= \frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha}_{t-1}\right) x_{t}+\sqrt{\alpha_{t-1}}\left(1-\alpha_{t}\right) \color{red}\hat{x}_{\theta}(x_t,t)}{1-\bar{\alpha}_{t}} \quad\quad(58)
\end{align}
$$

が成立する。

----
# 拡散モデルの学習アルゴリズム -2
$(56), (58)$  式が成立するとき、$KL$ ダイバージェンスは $(39)$ 式に代入する形で次式、
$$
\begin{align}
&D_{\mathrm{KL}}\left(q\left(x_{t-1} \mid x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} \mid x_{t}\right)\right) \\

&=\frac{1}{2 \sigma_{q}^{2}(t)}\left\|\mu_{\theta}\left(x_{t}, t\right)-\mu_{q}\left(x_{t}, x_{0}\right)\right\|^{2} \quad\quad(39) \\

&= \frac{1}{2 \sigma_{q}^{2}(t)}\left( \frac{\sqrt{\alpha_{t-1}}\left(1-\alpha_{t}\right)}{1-\bar{\alpha}_{t}} \right)^2\left\|\hat{x}_{\theta}(x_t,t) - x_{0} \right\|^{2} 
\tag{59}
\end{align}
$$

となる。

---
# 拡散モデルの学習アルゴリズム -3

---
# 拡散モデルの学習アルゴリズム -4
## ノイズを予測するニューラルネットワーク
$(50)$ 式について考える。

$$
\begin{align}
q\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)=\mathcal{N}\left(\boldsymbol{x}_t ; \sqrt{\bar{\alpha}_t} \boldsymbol{x}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)
\tag{50}
\end{align}
$$

$q\left(x_t \mid x_0\right)$ からのサンプルは、再パラメータ化トリックによって、次式で表される。

$$
\begin{align}
\varepsilon & \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
x_t & =\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t }\varepsilon
\tag{60}
\end{align}
$$

---
# 拡散モデルの学習アルゴリズム -5
$(60)$ 式を等式変形すると、次式が成立する。

$$
\begin{align}
x_0

=\frac{x_t-\sqrt{1-\bar{\alpha}_t} \varepsilon}{\sqrt{\bar{\alpha}_t}}
\tag{61}
\end{align}
$$

$(61)$ 式を $(56)$ 式に代入して式展開すると、

$$
\begin{align}
\mu_q\left(x_t, x_0\right) 

& =\frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right) x_t+\sqrt{\alpha_{t-1}}\left(1-\alpha_t\right) x_0}{1-\bar{\alpha}_t} \quad\quad(56)\\

&=\frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right) x_t+\sqrt{\alpha_{t-1}}\left(1-\alpha_t\right) \frac{x_t-\sqrt{1-\bar{\alpha}_t} \varepsilon}{\sqrt{\bar{\alpha}_{t}}}}{1-\bar{\alpha}_t}\\

&=\frac{ \sqrt{\alpha_t\bar{\alpha}_t} \left(1-\bar{\alpha}_{t-1}\right) x_t + \sqrt{\alpha_{t-1}} \left(1-\alpha_t\right) x_t - \sqrt{\alpha_{t-1}(1-\bar{\alpha}_t)} \left(1-\alpha_t\right) \varepsilon }{(1-\bar{\alpha}_t)\sqrt{\bar{\alpha}_{t}}}
\end{align}
$$

---
# 拡散モデルの学習アルゴリズム -6
(続き)
$$
\begin{align}
&=\frac{1}{\sqrt{\bar{\alpha}_{t}}}\left[\frac{ \sqrt{\alpha_t\bar{\alpha}_t} \left(1-\bar{\alpha}_{t-1}\right) + \sqrt{\alpha_{t-1}} \left(1-\alpha_t\right) }{(1-\bar{\alpha}_t)}x_t -\frac{\sqrt{\alpha_{t-1}}\left(1-\alpha_t\right)}{\sqrt{1-\bar{\alpha}_t}}\varepsilon \right] \quad(62)
\end{align}
$$

$\bar{\alpha}_t$ は $\alpha_{t} \alpha_{t-1} \cdots \alpha_{1}$ と定義したので、$\bar{\alpha}_t = \alpha_t\bar{\alpha}_{t-1}$ となる。よって、

$$
\begin{align}
&\frac{\sqrt{\bar{\alpha}_{t-1}}}{\sqrt{\bar{\alpha}_{t}}}

\left[\frac{ \alpha_t \left(1-\bar{\alpha}_{t-1}\right) + \frac{1}{\sqrt{\bar{\alpha}_{t-2}}}\left(1-\alpha_t\right) }{(1-\bar{\alpha}_t)}x_t  - \frac{\frac{1}{\sqrt{\bar{\alpha}_{t-2}}}\left(1-\alpha_t\right)}{\sqrt{1-\bar{\alpha}_t}}\varepsilon \right]\\

&=\frac{1}{\sqrt{\alpha_{t}}}

\left[\frac{ \alpha_t \left(1-\bar{\alpha}_{t-1}\right) + \frac{1}{\sqrt{\bar{\alpha}_{t-2}}}\left(1-\alpha_t\right) }{(1-\bar{\alpha}_t)}x_t  - \frac{\frac{1}{\sqrt{\bar{\alpha}_{t-2}}}\left(1-\alpha_t\right)}{\sqrt{1-\bar{\alpha}_t}}\varepsilon \right] \quad(63)
\end{align}
$$

---
# 拡散モデルの学習アルゴリズム -7
ここで、限りなく $1$ に近い値の平方根が、より $1$ に近づくことを考える。平方根を $\frac{1}{2}$ 乗として二項定理の近似でも分かるが、単純に $\sqrt{0.81}=0.9$ を想像するのが簡単。

$$
\begin{align}
& =\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \varepsilon\right)
\tag{62}
\end{align}
$$

# 拡散モデルの学習アルゴリズム -6
この式に対応させるように $\mu_\theta\left(x_t, t\right)$ を書き換えると、次のようになります。
$$
\mu_\theta\left(x_t, t\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \varepsilon_\theta\left(x_t, t\right)\right)
$$

ことでは $\varepsilon_\theta\left(x_t, t\right)$ がニューラルネットワークの出力を表します。このとき KL 夕 イハージェンスは次のように計算できます。
$$
\begin{aligned}
& D_{K_L}\left(q\left(x_{t-1} \mid x_t, x_0\right) \| p_\theta\left(x_{t-1} \mid x_t\right)\right)=\frac{1}{2 \sigma_q^2(t)}\left\|\mu_\theta\left(x_t, t\right)-\mu_q\left(x_t, x_0\right)\right\|^2 \\
& =\frac{1}{2 \sigma_q^2(t)} \frac{\left(1-\alpha_t\right)^2}{\left(1-\bar{\alpha}_t\right) \alpha_t}\left\|\varepsilon_\theta\left(x_t, t\right)-\varepsilon\right\|^2 \\
&
\end{aligned}
$$

---
\( t \)
\#○んたということてす。
$$
\operatorname{LOSS}\left(x_{0} ; \theta\right)=\left\|\varepsilon_{\theta}\left(x_{t}, t\right)-\varepsilon\right\|^{2}
$$

このシンフルな报失閃数によって拡散モデルが学習できます。この挸）太临厂ルコリスムは、囬似コードで次のように表されます。

桩散モデルの学習アルゴリズム（ノイズ予測版）

---
# （ノイズ予測型の）拡散モデルの学習アルゴリズム
1: Repeat:
2: $x_{0}$ を学習データよりランダムに取得
3: $\quad t \sim U\{1, T\} \quad$ (一様分布より整数 $t$ を生成)
4: $\quad \varepsilon \sim \mathcal{N}(0, \mathrm{I})$
5: $\quad x_{t}=\sqrt{\bar{\alpha}_{t}} x_{0}+\sqrt{1-\bar{\alpha}_{t} \varepsilon}$
6: $\quad \operatorname{LOSS}\left(x_{0} ; \theta\right)=\left\|\varepsilon_{\theta}\left(x_{t}, t\right)-\varepsilon\right\|^{2}$
7: $\quad \frac{\partial}{\partial \theta} \operatorname{LOSS}\left(\boldsymbol{x}_{0} ; \boldsymbol{\theta}\right)$ を求め、勾配法でパラメータを更新

---

$$
\begin{align}
\frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right) x_t+\sqrt{\alpha_{t-1}}\left(1-\alpha_t\right) \frac{x_t-\sqrt{1-\bar{\alpha}_t} \varepsilon}{\sqrt{\bar{\alpha}_{t}}}}{1-\bar{\alpha}_t}\\

=\frac{ \sqrt{\alpha_t\bar{\alpha}_t} \left(1-\bar{\alpha}_{t-1}\right) x_t + \sqrt{\alpha_{t-1}} \left(1-\alpha_t\right) x_t - \sqrt{\alpha_{t-1}(1-\bar{\alpha}_t)} \left(1-\alpha_t\right) \varepsilon }{(1-\bar{\alpha}_t)\sqrt{\bar{\alpha}_{t}}}
\end{align}
$$

$$
\begin{align}
\frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \varepsilon \right)
\end{align}
$$


